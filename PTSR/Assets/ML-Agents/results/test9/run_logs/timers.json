{
    "name": "root",
    "gauges": {
        "RaceAgent.Policy.Entropy.mean": {
            "value": 1.0799728631973267,
            "min": 1.0799728631973267,
            "max": 1.40977144241333,
            "count": 67
        },
        "RaceAgent.Policy.Entropy.sum": {
            "value": 10799.728515625,
            "min": 8131.5615234375,
            "max": 14065.1572265625,
            "count": 67
        },
        "RaceAgent.Step.mean": {
            "value": 999880.0,
            "min": 339965.0,
            "max": 999880.0,
            "count": 67
        },
        "RaceAgent.Step.sum": {
            "value": 999880.0,
            "min": 339965.0,
            "max": 999880.0,
            "count": 67
        },
        "RaceAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -3.6515719890594482,
            "min": -4.9547247886657715,
            "max": -1.9623548984527588,
            "count": 67
        },
        "RaceAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -292.1257629394531,
            "min": -396.37799072265625,
            "max": -88.30596923828125,
            "count": 67
        },
        "RaceAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 1.0397504568099976,
            "min": 0.9797407984733582,
            "max": 4.45728874206543,
            "count": 67
        },
        "RaceAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 83.18003845214844,
            "min": 78.37926483154297,
            "max": 338.6483154296875,
            "count": 67
        },
        "RaceAgent.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 941.7,
            "max": 999.0,
            "count": 67
        },
        "RaceAgent.Environment.EpisodeLength.sum": {
            "value": 9990.0,
            "min": 4995.0,
            "max": 10798.0,
            "count": 67
        },
        "RaceAgent.Environment.CumulativeReward.mean": {
            "value": -30.080373998731375,
            "min": -53.85856741666794,
            "max": -27.434124191105365,
            "count": 67
        },
        "RaceAgent.Environment.CumulativeReward.sum": {
            "value": -300.80373998731375,
            "min": -522.7398476228118,
            "max": -269.2928370833397,
            "count": 67
        },
        "RaceAgent.Policy.ExtrinsicReward.mean": {
            "value": -30.080373998731375,
            "min": -53.85856741666794,
            "max": -27.434124191105365,
            "count": 67
        },
        "RaceAgent.Policy.ExtrinsicReward.sum": {
            "value": -300.80373998731375,
            "min": -522.7398476228118,
            "max": -269.2928370833397,
            "count": 67
        },
        "RaceAgent.Policy.CuriosityReward.mean": {
            "value": 9.955597150325776,
            "min": 0.0,
            "max": 41.27277318239212,
            "count": 67
        },
        "RaceAgent.Policy.CuriosityReward.sum": {
            "value": 99.55597150325775,
            "min": 0.0,
            "max": 412.7277318239212,
            "count": 67
        },
        "RaceAgent.Losses.PolicyLoss.mean": {
            "value": 0.04774925926703873,
            "min": 0.045034177493871536,
            "max": 0.05399338673247257,
            "count": 67
        },
        "RaceAgent.Losses.PolicyLoss.sum": {
            "value": 0.09549851853407745,
            "min": 0.045034177493871536,
            "max": 0.10798677346494515,
            "count": 67
        },
        "RaceAgent.Losses.ValueLoss.mean": {
            "value": 0.008138858317397534,
            "min": 0.0006589557818369939,
            "max": 0.35226905571296807,
            "count": 67
        },
        "RaceAgent.Losses.ValueLoss.sum": {
            "value": 0.01627771663479507,
            "min": 0.0007710020599188283,
            "max": 0.7045381114259361,
            "count": 67
        },
        "RaceAgent.Policy.LearningRate.mean": {
            "value": 9.790996084000078e-07,
            "min": 9.790996084000078e-07,
            "max": 0.0001651367839453,
            "count": 67
        },
        "RaceAgent.Policy.LearningRate.sum": {
            "value": 1.9581992168000157e-06,
            "min": 1.9581992168000157e-06,
            "max": 0.00032642756942900006,
            "count": 67
        },
        "RaceAgent.Policy.Epsilon.mean": {
            "value": 0.10019580000000002,
            "min": 0.10019580000000002,
            "max": 0.13302734999999996,
            "count": 67
        },
        "RaceAgent.Policy.Epsilon.sum": {
            "value": 0.20039160000000003,
            "min": 0.1067496,
            "max": 0.26528550000000006,
            "count": 67
        },
        "RaceAgent.Policy.Beta.mean": {
            "value": 1.3876840000000032e-05,
            "min": 1.3876840000000032e-05,
            "max": 0.00066394153,
            "count": 67
        },
        "RaceAgent.Policy.Beta.sum": {
            "value": 2.7753680000000065e-05,
            "min": 2.7753680000000065e-05,
            "max": 0.0013126529,
            "count": 67
        },
        "RaceAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.9388944807648658,
            "min": 0.873631692007184,
            "max": 47.07750726222992,
            "count": 67
        },
        "RaceAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 1.8777889615297316,
            "min": 1.0611643612384796,
            "max": 47.07750726222992,
            "count": 67
        },
        "RaceAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 1.1755963234603404,
            "min": 1.1755963234603404,
            "max": 21.15056520819664,
            "count": 67
        },
        "RaceAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 2.3511926469206808,
            "min": 1.2110843235254287,
            "max": 21.15056520819664,
            "count": 67
        },
        "RaceAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 67
        },
        "RaceAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 67
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1718521304",
        "python_version": "3.9.19 (main, Mar 21 2024, 17:21:27) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\henry\\anaconda3\\envs\\agent2\\Scripts\\mlagents-learn config/config.yaml --run-id=test9 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1718541928"
    },
    "total": 20623.7350178,
    "count": 1,
    "self": 0.05519570000251406,
    "children": {
        "run_training.setup": {
            "total": 0.14190619999999976,
            "count": 1,
            "self": 0.14190619999999976
        },
        "TrainerController.start_learning": {
            "total": 20623.5379159,
            "count": 1,
            "self": 19.085628600292694,
            "children": {
                "TrainerController._reset_env": {
                    "total": 30.2542471,
                    "count": 1,
                    "self": 30.2542471
                },
                "TrainerController.advance": {
                    "total": 20574.033529199703,
                    "count": 665796,
                    "self": 19.4616024001225,
                    "children": {
                        "env_step": {
                            "total": 18252.145052499265,
                            "count": 665796,
                            "self": 13260.847361599917,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 4978.522902499539,
                                    "count": 665796,
                                    "self": 61.94207740010552,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 4916.580825099433,
                                            "count": 665683,
                                            "self": 4916.580825099433
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 12.774788399808138,
                                    "count": 665796,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 20567.60184859975,
                                            "count": 665796,
                                            "is_parallel": true,
                                            "self": 8184.932731799809,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006794000000027722,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00031300000000911155,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0003663999999936607,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0003663999999936607
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 12382.66843739994,
                                                    "count": 665796,
                                                    "is_parallel": true,
                                                    "self": 76.8175517987438,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 64.69847449982487,
                                                            "count": 665796,
                                                            "is_parallel": true,
                                                            "self": 64.69847449982487
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 11969.792184699585,
                                                            "count": 665796,
                                                            "is_parallel": true,
                                                            "self": 11969.792184699585
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 271.36022640178624,
                                                            "count": 665796,
                                                            "is_parallel": true,
                                                            "self": 144.00447550308883,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 127.35575089869741,
                                                                    "count": 2663184,
                                                                    "is_parallel": true,
                                                                    "self": 127.35575089869741
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2302.4268743003167,
                            "count": 665796,
                            "self": 21.30778450157095,
                            "children": {
                                "process_trajectory": {
                                    "total": 120.27153219875484,
                                    "count": 665796,
                                    "self": 119.79090799875442,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4806242000004204,
                                            "count": 2,
                                            "self": 0.4806242000004204
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 2160.847557599991,
                                    "count": 129,
                                    "self": 1255.5835001998303,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 905.2640574001607,
                                            "count": 25800,
                                            "self": 905.2640574001607
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.4000000848900527e-06,
                    "count": 1,
                    "self": 2.4000000848900527e-06
                },
                "TrainerController._save_models": {
                    "total": 0.16450860000259127,
                    "count": 1,
                    "self": 0.04677640000227257,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1177322000003187,
                            "count": 1,
                            "self": 0.1177322000003187
                        }
                    }
                }
            }
        }
    }
}